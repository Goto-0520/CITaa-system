# ========================================
# ã‚»ãƒ«1: å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨èª­ã¿è¾¼ã¿
# ========================================
!pip install openpyxl -q

import pandas as pd
import numpy as np
from google.colab import files
import io
import re

print("âœ“ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸ")

# ========================================
# ã‚»ãƒ«2: å…ƒãƒ‡ãƒ¼ã‚¿ï¼ˆãƒã‚¹ã‚¿ãƒ¼ãƒªã‚¹ãƒˆï¼‰ã®è¨­å®š
# ========================================
# ã“ã“ã§æ°åãƒªã‚¹ãƒˆã‚’æ›´æ–°ã§ãã¾ã™
master_names = [
    "å¹³å±± çœŸè¡£", "æ¾æœ¬ æ·³å¹³", "å¾Œè—¤ å¯›æ˜", "å¯’æ²³æ±Ÿ èŠ±ä½³", "æ¾å³¶ æ˜‚æ±°",
    "æ¤æ‘ æµç†", "è—¤ç”° å¤§è¼", "å®®å³¶ é¼å¸", "æµ…å· æŸŠå“‰", "æ¾ç”° ç©º",
    "å²¡ç”° è’¼æœª", "ä½è—¤ æ˜ä¾", "é™³ ä¸–ç‘œ", "åŠ è—¤ ç›´", "è¨ˆè‰¯ æ­å¹³",
    "ä½ã€…æœ¨ å“å‰", "ç™¾ç”° èˆªå¤§", "æ¨ªç”° é›„å·±", "å‰ç”° æ ¼", "é«˜æœ¨ è£•ä»‹",
    "ç‰è°· ä¿¡ä»‹", "æ±Ÿåˆ©å· è¼", "å°æ²¢ çµ¢ç¾", "æˆ¸ç”° ã„ã¶ã", "æ¿±é‡ æ˜ æ–—",
    "å±±æœ¬ ç…§çœŸ", "æœ¨æ‘ é­æ–—", "ç”°ä¸­ å„ªæ–—", "å¹³é‡ å°æ¬¡éƒ", "é½‹è—¤ å…‰å…µ",
    "é«˜æ©‹ å…‰", "çŸ³æ©‹ å¿«", "ä¼Šè—¤ å’²å¤ª", "å‚ é¼å¹³", "ç”°é‚Š èˆœ",
    "æªœå±± å’Œå¹¸", "å¢—æ°¸ ä¼¶å¸", "é‡‘æ¾¤ é¢¯å¤§", "ç®•è¼ª é™½å¤ª", "ä¸­å· é›„ä»‹",
    "å¤ªç”° å®—å³", "é‡‘ä¸¸ ç¢ç£¨", "ä½è—¤ å˜‰é«˜", "å¡™ å¤§ä½‘", "åŠ æˆ‘ ç‰ä¸–",
    "ç¯‰åŸ å¤§åŠ©", "é¶´å²¡ æ­£ä¹Ÿ", "å¤©è¾° æ˜‚å¹³", "ä½ä¹…é–“ å„ªå¦ƒ", "æ–°å±… å„ªç ",
    "å·å£ å¤§æ™´", "æ²³é‡ å­ç´€", "å²¡æœ¬ å¤§è¼", "å·æœ¬ éš†å¤ª", "ç¯ ç”° ç«œä¹‹ä»‹",
    "é«™è¦‹æ¾¤ æ­£äºº", "å¯ºå°¾ å„ªå¸Œ", "ç¾½å±± ä¿Šå¸Œ", "ä½è—¤ ç‰æƒº", "å ¤ åƒçœŸ",
    "é˜¿ä¹… æ­©å¶", "ä½ä¼¯ è³¢æ²»", "æµ…äº• å¥å‡›", "ç‰‡å¶‹ æ˜‡å¤§", "é«™æ©‹ åºƒå¿—",
    "ä½ã€…æœ¨ ç”ŸçœŸ", "è¶Šå· éŸ¿ç¨€", "å¤©é‡ è“®é£›", "æ¼†é–“ è™ä¹‹ä»‹", "å¤§å›³ å´‡ä»‹",
    "åŒ—ä¸Š é§¿ä»‹", "æ²³é‡ çœŸå¹¸", "åŠæ¾¤ å¥ˆæ¨¹", "ä¸Šç”° æ‚ é¦¬", "é‡‘æ¾¤ é¾èª ",
    "ä¸­å±± ä¿®å…", "æ¸¡è¾º äº®çœŸ", "å²¡éƒ¨ å„ªå¸Œ", "æ‰æœ¬ æ˜‡æ±°æœ—", "ã‚­ãƒ  ãƒ†ãƒŸãƒ³",
    "ç¬¹å· æ‹“çœŸ", "æ’å‰ çœå¾", "å¯ºå³¶ æ±éŸ³", "ä½ã€…æœ¨ é™½èœ", "å…«æœ¨ ç§€ç« ",
    "èŠ¦å· ç¾æ¡œ", "ä¸Šç”° ç„å˜‰", "æŸ“è°· å¥æ–—", "è°· æ‹“æµ·", "æ–°å¦» ç‘›",
    "èµ¤ä½ å¤å­£", "å¤§ä¹…ä¿ å£®è‘µ", "ç¥å®® æˆåˆ©", "æ¨ªå±± æ™ºç´€", "ç‹ åŠ›æ´‹",
    "å°é‡ ä¸€æ¨¹", "å°åŸ æ°¸å¯›", "æ¸…æ°´ ã‚ãŠã„", "æ¸…æ°´ æ˜ ç©º", "ä¼Šè—¤ ä¸€æˆ",
    "å®‡é‡ ç¥å¤ªéƒ", "æˆç”° éš¼äºº", "å®ˆ èˆªå¤§"
]

print(f"âœ“ ãƒã‚¹ã‚¿ãƒ¼ãƒªã‚¹ãƒˆ: {len(master_names)}åç™»éŒ²æ¸ˆã¿")
print("â€» ã“ã®ãƒªã‚¹ãƒˆã‚’æ›´æ–°ã™ã‚‹å ´åˆã¯ã€ä¸Šè¨˜ã® master_names ã‚’ç·¨é›†ã—ã¦ãã ã•ã„")


# ========================================
# ã‚»ãƒ«3: ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
# ========================================
def upload_file():
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦èª­ã¿è¾¼ã‚€"""
    print("ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„...")
    uploaded = files.upload()

    if not uploaded:
        print("âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        return None

    filename = list(uploaded.keys())[0]
    print(f"âœ“ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {filename}")

    # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’åˆ¤å®šã—ã¦èª­ã¿è¾¼ã¿
    if filename.endswith('.xlsx') or filename.endswith('.xls'):
        df = pd.read_excel(io.BytesIO(uploaded[filename]), sheet_name=0)
    elif filename.endswith('.csv'):
        df = pd.read_csv(io.BytesIO(uploaded[filename]))
    else:
        print("âŒ å¯¾å¿œã—ã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™ï¼ˆxlsx, xls, csv ã®ã¿å¯¾å¿œï¼‰")
        return None

    print(f"âœ“ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df)}è¡Œ Ã— {len(df.columns)}åˆ—")
    return df

print("âœ“ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸ")


# ========================================
# ã‚»ãƒ«4: æ°åæ¬„è‡ªå‹•æ¤œå‡ºæ©Ÿèƒ½ã¨åå‰æ­£è¦åŒ–
# ========================================
def normalize_name(name):
    """
    æ°åã‚’æ­£è¦åŒ–ï¼ˆç©ºç™½ã®æœ‰ç„¡ã¨ç•°ä½“å­—ã‚’çµ±ä¸€ï¼‰
    ä¾‹: "åƒè‘‰å·¥å¤§" ã¨ "åƒè‘‰ å·¥å¤§" ã‚’åŒä¸€è¦–
    ä¾‹: "é«˜æ©‹" ã¨ "é«™æ©‹" ã‚’åŒä¸€è¦–
    """
    if pd.isna(name):
        return ""
    name_str = str(name).strip()

    # å…¨è§’ãƒ»åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ã€ã‚¿ãƒ–ãªã©ã‚’å‰Šé™¤
    normalized = re.sub(r'\s+', '', name_str)

    # ç•°ä½“å­—ã‚’çµ±ä¸€ï¼ˆã‚ˆãä½¿ã‚ã‚Œã‚‹æ¼¢å­—ã®ç•°ä½“å­—ï¼‰
    variant_map = {
        'é«™': 'é«˜',  # ã¯ã—ã”ã ã‹
        'ï¨‘': 'å´',  # ãŸã¤ã•ã
        'é½‹': 'æ–',
        'é½Š': 'æ–',
        'æ–‰': 'æ–',
        'é‚‰': 'è¾º',
        'é‚Š': 'è¾º',
        'æ¾¤': 'æ²¢',
        'ç€¨': 'ç€¬',
        'æ¿µ': 'æµœ',
        'æ¿±': 'æµœ',
        'æ ': 'æŸ³',
        'å¡š': 'å¡š',  # æ—§å­—
        'å³¯': 'å³°',
        'å¶‹': 'å³¶',
        'å¶Œ': 'å³¶',
        'æ¸¡': 'æ¸¡',  # æ—§å­—
        'èˆ˜': 'é¤¨',
        'è¬': 'ä¸‡',
        'äº': 'äºœ',
        'æƒ ': 'æµ',
        'å»£': 'åºƒ',
        'å¾·': 'å¾³',
        'å¯¶': 'å®',
        'å¯¦': 'å®Ÿ',
        'é¾': 'ç«œ',
    }

    for variant, standard in variant_map.items():
        normalized = normalized.replace(variant, standard)

    return normalized

def detect_name_column(df):
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰æ°åæ¬„ã‚’è‡ªå‹•æ¤œå‡ºã™ã‚‹
    """
    # æ°åæ¬„ã¨ã—ã¦å¯èƒ½æ€§ã®é«˜ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    name_keywords = ['æ°å', 'åå‰', 'å§“å', 'name', 'ãªã¾ãˆ', 'ç¤¾å“¡å', 'å­¦ç”Ÿå', 'å—è¬›è€…å']

    # 1. ã‚«ãƒ©ãƒ åã‹ã‚‰æ¤œå‡º
    for col in df.columns:
        col_str = str(col).lower()
        for keyword in name_keywords:
            if keyword in col_str:
                print(f"âœ“ æ°åæ¬„ã‚’æ¤œå‡º: '{col}'")
                return col

    # 2. ãƒ‡ãƒ¼ã‚¿ã®å†…å®¹ã‹ã‚‰æ¤œå‡ºï¼ˆæ—¥æœ¬äººåã‚‰ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
    for col in df.columns:
        sample_data = df[col].dropna().head(10).astype(str)

        # æ—¥æœ¬èªæ–‡å­—ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        match_count = 0
        for val in sample_data:
            val_clean = val.strip()
            # 2-15æ–‡å­—ã§ã€æ—¥æœ¬èªæ–‡å­—ã‚’å«ã‚€
            if 2 <= len(val_clean) <= 15:
                # æ—¥æœ¬èªæ–‡å­—ï¼ˆã²ã‚‰ãŒãªã€ã‚«ã‚¿ã‚«ãƒŠã€æ¼¢å­—ï¼‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹
                has_japanese = any('\u3040' <= c <= '\u309F' or  # ã²ã‚‰ãŒãª
                                 '\u30A0' <= c <= '\u30FF' or  # ã‚«ã‚¿ã‚«ãƒŠ
                                 '\u4E00' <= c <= '\u9FFF'     # æ¼¢å­—
                                 for c in val_clean)
                if has_japanese:
                    match_count += 1

        if match_count >= 5:  # 10ä»¶ä¸­5ä»¶ä»¥ä¸ŠãŒåå‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ä¸€è‡´
            print(f"âœ“ æ°åæ¬„ã‚’æ¤œå‡ºï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰ï¼‰: '{col}'")
            return col

    print("âš ï¸ æ°åæ¬„ã‚’è‡ªå‹•æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
    print("åˆ©ç”¨å¯èƒ½ãªã‚«ãƒ©ãƒ :")
    for i, col in enumerate(df.columns):
        print(f"  [{i}] {col}")

    return None

print("âœ“ æ°åæ¬„æ¤œå‡ºæ©Ÿèƒ½ã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸ")

# ========================================
# ã‚»ãƒ«5: æ¯”è¼ƒå®Ÿè¡Œï¼ˆãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼‰
# ========================================
print("=" * 50)
print("ğŸ“ ç¢ºèªã—ãŸã„ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
print("   ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—ã¾ãŸã¯é¸æŠï¼‰")
print("=" * 50)

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
check_df = upload_file()

if check_df is not None:
    # æ°åæ¬„ã‚’æ¤œå‡º
    name_col = detect_name_column(check_df)

    if name_col is None:
        print("\næ‰‹å‹•ã§ã‚«ãƒ©ãƒ ã‚’é¸æŠã—ã¦ãã ã•ã„:")
        col_index = int(input("ã‚«ãƒ©ãƒ ç•ªå·ã‚’å…¥åŠ›: "))
        name_col = check_df.columns[col_index]

    # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ­£è¦åŒ–
    check_names_raw = check_df[name_col].dropna().astype(str).str.strip().unique()

    # ãƒã‚¹ã‚¿ãƒ¼ãƒªã‚¹ãƒˆã‚’æ­£è¦åŒ–ï¼ˆç©ºç™½ãªã—ï¼‰
    master_normalized = {normalize_name(name): name for name in master_names}
    master_set_normalized = set(master_normalized.keys())

    # ç¢ºèªãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–
    check_normalized = {normalize_name(name): name for name in check_names_raw}
    check_set_normalized = set(check_normalized.keys())

    print(f"\nâœ“ ç¢ºèªãƒ‡ãƒ¼ã‚¿: {len(check_names_raw)}åï¼ˆé‡è¤‡é™¤å¤–å¾Œ: {len(check_set_normalized)}åï¼‰")

    # æ¯”è¼ƒå‡¦ç†ï¼ˆæ­£è¦åŒ–ã—ãŸåå‰ã§æ¯”è¼ƒï¼‰
    missing_normalized = sorted(master_set_normalized - check_set_normalized)

    # å…ƒã®è¡¨è¨˜ã«æˆ»ã™
    missing_people = [master_normalized[norm] for norm in missing_normalized]

    # çµæœè¡¨ç¤º
    print("\n" + "=" * 50)
    print("ğŸ“Š æ¯”è¼ƒçµæœ")
    print("=" * 50)
    print(f"ãƒã‚¹ã‚¿ãƒ¼ãƒªã‚¹ãƒˆ: {len(master_names)}å")
    print(f"ç¢ºèªãƒ‡ãƒ¼ã‚¿: {len(check_set_normalized)}å")
    print(f"ä¸åœ¨è€…: {len(missing_people)}å")
    print("=" * 50)

    if missing_people:
        print("\nâŒ ç¢ºèªãƒ‡ãƒ¼ã‚¿ã«ã„ãªã„äºº:")
        for i, name in enumerate(missing_people, 1):
            print(f"  {i}. {name}")
    else:
        print("\nâœ… å…¨å“¡ãŒç¢ºèªãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã¦ã„ã¾ã™!")

    # è¿½åŠ ã§ã„ã‚‹äººï¼ˆãƒã‚¹ã‚¿ãƒ¼ã«ãªã„äººï¼‰ã‚‚è¡¨ç¤º
    extra_normalized = sorted(check_set_normalized - master_set_normalized)
    extra_people = [check_normalized[norm] for norm in extra_normalized]

    if extra_people:
        print(f"\nâš ï¸ ãƒã‚¹ã‚¿ãƒ¼ãƒªã‚¹ãƒˆã«ãªã„äººï¼ˆ{len(extra_people)}åï¼‰:")
        for i, name in enumerate(extra_people, 1):
            print(f"  {i}. {name}")
